{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Navigation\n","1. [Start Here](hey.ipynb)\n","1. [Load Data and Clean](/eda.ipynb)\n","1. [To Clean, or Not To Clean?](eval_v1.ipynb)\n","1. Generate Datasets\n","    1. [Faker Naive](faker_naive.ipynb)\n","    1. [Faker Plus](faker_plus.ipynb)\n","    1. [SDV Naive](sdv_v1.ipynb)\n","    1. [SDV More Better](sdv_v2.ipynb)\n","    1. [SDV TVAE]()\n","1. Compare and Evaluate Performance\n","    1. [First impressions](eval_v2.ipynb)\n","    1. [Loan financial models](eval_v3.ipynb)\n","    1. [Predicting default risk](eval_v4.ipynb)\n","    1. [How hackable]()"]},{"cell_type":"markdown","metadata":{"cell_id":"bcab9ec4e436441199a36637448cd504","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Logistic regression model for predicting loan default risk"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"12769136d1894180b61dedd453284672","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":374,"execution_start":1728623029108,"source_hash":"71b7fa18"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","import warnings\n","\n","# Suppress common warnings that do not impact results\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","def load_and_prepare_data(df):\n","    \"\"\"\n","    Prepare the DataFrame for modeling.\n","    \n","    Parameters:\n","    - df: DataFrame, the input data containing loan data.\n","\n","    Returns:\n","    - df: DataFrame, prepared data for modeling.\n","    \"\"\"\n","    try:\n","        print(\"Data loaded successfully.\")\n","\n","        # Filter to keep only relevant columns\n","        relevant_columns = [\n","            'loan_amnt', 'unified_dti', 'unified_annual_inc', \n","            'fico_range_avg', 'home_ownership', 'sub_grade', \n","            'loan_status', 'issue_d'\n","        ]\n","\n","        # Ensure all relevant columns exist in the DataFrame\n","        missing_cols = set(relevant_columns) - set(df.columns.tolist())\n","        if missing_cols:\n","            raise ValueError(f\"Missing columns in the dataset: {missing_cols}\")\n","\n","        # Select relevant columns\n","        df = df[relevant_columns].copy()  # Use .copy() to avoid setting on a slice\n","\n","        # Convert 'issue_d' to datetime and extract the year\n","        df['issue_d'] = pd.to_datetime(df['issue_d'], errors='coerce')\n","        df['issue_year'] = df['issue_d'].dt.year  # Extract year for further analysis\n","\n","        return df\n","\n","    except Exception as e:\n","        print(f\"An error occurred while preparing data: {e}\")\n","        raise\n","\n","def encode_features(df):\n","    \"\"\"\n","    Encode categorical features and the target variable.\n","\n","    Parameters:\n","    - df: DataFrame, the input data containing categorical features.\n","\n","    Returns:\n","    - df: DataFrame, the input data with encoded features.\n","    \"\"\"\n","    # Check for unique values in 'loan_status' before encoding\n","    if 'loan_status' not in df or df['loan_status'].isnull().any():\n","        raise ValueError(\"The 'loan_status' column is missing or contains null values.\")\n","\n","    unique_labels = df['loan_status'].unique()\n","    expected_labels = ['Default', 'Fully Paid']\n","\n","    # Check for unexpected values\n","    if not set(unique_labels).issubset(expected_labels):\n","        raise ValueError(f\"Unexpected values in 'loan_status': {unique_labels}. Expected: {expected_labels}\")\n","\n","    # Encode the target variable: 'Default' = 1, 'Fully Paid' = 0\n","    df['loan_status'] = df['loan_status'].apply(lambda x: 1 if x == 'Default' else 0)\n","\n","    # Check if encoding was successful\n","    if df['loan_status'].isnull().any():\n","        raise ValueError(\"Encoding of 'loan_status' resulted in null values.\")\n","\n","    # Encode categorical features using Label Encoder\n","    categorical_features = ['home_ownership', 'sub_grade']\n","    for column in categorical_features:\n","        le = LabelEncoder()\n","        df[column] = le.fit_transform(df[column].astype(str))\n","\n","    return df\n","\n","def train_model(X_train, y_train):\n","    \"\"\"\n","    Train the Logistic Regression model.\n","\n","    Parameters:\n","    - X_train: DataFrame, features for training.\n","    - y_train: Series, target variable for training.\n","\n","    Returns:\n","    - model: LogisticRegression, trained model.\n","    \"\"\"\n","    # Ensure y_train is a binary array\n","    if not pd.api.types.is_numeric_dtype(y_train):\n","        raise ValueError(\"y_train must be numeric.\")\n","\n","    model = LogisticRegression(max_iter=500, solver='lbfgs', n_jobs=-1)  # Use all available CPU cores\n","    model.fit(X_train, y_train)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test):\n","    \"\"\"\n","    Evaluate the model and return performance metrics.\n","\n","    Parameters:\n","    - model: LogisticRegression, the trained model.\n","    - X_test: DataFrame, features for testing.\n","    - y_test: Series, true labels for testing.\n","\n","    Returns:\n","    - results: dict, containing accuracy, F1 score, and classification report.\n","    \"\"\"\n","    predictions = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, predictions)\n","    f1 = f1_score(y_test, predictions)\n","    report = classification_report(y_test, predictions, output_dict=True)\n","\n","    results = {\n","        'accuracy': accuracy,\n","        'f1_score': f1,\n","        'classification_report': report\n","    }\n","\n","    return results\n","\n","def print_model_formula(model, feature_names):\n","    \"\"\"\n","    Print the logistic regression model formula.\n","\n","    Parameters:\n","    - model: LogisticRegression, the trained model.\n","    - feature_names: list, names of the features.\n","    \"\"\"\n","    coefficients = model.coef_[0]\n","    intercept = model.intercept_[0]\n","    formula = f\"Logit(P(Default)) = {intercept:.4f} + \" + \\\n","              \" + \".join([f\"{coeff:.4f} * {name}\" for coeff, name in zip(coefficients, feature_names)])\n","    print(\"\\nModel Formula:\")\n","    print(formula)\n","\n","def save_results(results, output_file):\n","    \"\"\"\n","    Save the evaluation results to a CSV file.\n","\n","    Parameters:\n","    - results: dict, evaluation results to save.\n","    - output_file: str, the path to the output CSV file.\n","    \"\"\"\n","    # Create a DataFrame from the results\n","    report_df = pd.DataFrame(results['classification_report']).transpose()\n","    report_df.to_csv(output_file, index=True)\n","\n","    # Save accuracy and F1 score as separate entries\n","    summary_df = pd.DataFrame({\n","        'Metric': ['Accuracy', 'F1 Score'],\n","        'Value': [results['accuracy'], results['f1_score']]\n","    })\n","    \n","    # Append summary to the report\n","    summary_df.to_csv(output_file, mode='a', index=False)\n","\n","    print(f\"Results saved to {output_file}\")\n","\n","def main(df, output_file='evaluation_results.csv'):\n","    \"\"\"\n","    Main function to execute the loan default risk prediction.\n","\n","    Parameters:\n","    - df: DataFrame, the input data containing loan data.\n","    - output_file: str, the path to save evaluation results.\n","    \"\"\"\n","    # Prepare data\n","    df = load_and_prepare_data(df)\n","\n","    # Encode features\n","    df = encode_features(df)\n","\n","    # Define features (X) and target (y)\n","    X = df.drop(['loan_status', 'issue_d'], axis=1)  # Drop target and datetime\n","    y = df['loan_status']\n","\n","    # Additional check for y\n","    if y.isnull().any() or not set(y.unique()).issubset([0, 1]):\n","        raise ValueError(\"The target variable 'loan_status' must be binary (0 or 1) and cannot contain null values.\")\n","\n","    # Split the data into training and test sets with stratification\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42, stratify=y\n","    )\n","\n","    # Scale the features to improve model performance\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    # Train the model\n","    model = train_model(X_train, y_train)\n","\n","    # Print the model formula\n","    print_model_formula(model, X.columns)\n","\n","    # Evaluate the model\n","    results = evaluate_model(model, X_test, y_test)\n","\n","    # Save results to CSV\n","    save_results(results, output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8a65309ff9c14b66acd33a0a22a5c9a7","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":1,"execution_start":1728623048127,"source_hash":"796c70ed"},"outputs":[],"source":["# Replace 'path_to_file.csv' with the actual path to your CSV file\n","import os\n","plist=[]\n","paths = [os.environ[\"SYNTH_N\"], os.environ[\"SYNTH_G\"],\n","        os.environ[\"FAKER\"], os.environ[\"FAKER_P\"]]\n","\n","for p in paths:\n","    path = os.path.join(os.environ[\"PATH_START\"], p)\n","    plist.append(path)\n","\n","plist"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"307fc4058cf14e88909a7bc5b9307f9b","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":62267,"execution_start":1728623048183,"source_hash":"69bd01b1"},"outputs":[],"source":["# Get the filename for each path\n","for p in plist:\n","    # Get the basename of the path\n","    output_basename = os.path.basename(p)\n","    # Remove '.csv' from the basename\n","    output_basename = output_basename[:-4]\n","    output_basename = output_basename + '_evaluation_results.csv'\n","    print(output_basename)\n","    df = pd.read_csv(p, low_memory=False)\n","    main(df, output_file=output_basename)\n","    print('\\n\\n')"]},{"cell_type":"markdown","metadata":{"cell_id":"33247a8d7a264e48aceffc58a5826fbb","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### Decision Tree"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"96375f9786aa4c4b94ddf9ddda4cf563","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":1,"execution_start":1728623110495,"source_hash":"598ccf5f"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","from sklearn.metrics import accuracy_score, f1_score, classification_report\n","import graphviz\n","import warnings\n","\n","# Suppress common warnings that do not impact results\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","def load_and_prepare_data(df):\n","    \"\"\"\n","    Prepare the DataFrame for modeling.\n","    \n","    Parameters:\n","    - df: DataFrame, the input data containing loan data.\n","\n","    Returns:\n","    - df: DataFrame, prepared data for modeling.\n","    \"\"\"\n","    try:\n","        print(\"Data loaded successfully.\")\n","\n","        relevant_columns = [\n","            'loan_amnt', 'unified_dti', 'unified_annual_inc', \n","            'fico_range_avg', 'home_ownership', 'sub_grade', \n","            'loan_status', 'issue_d'\n","        ]\n","\n","        missing_cols = set(relevant_columns) - set(df.columns.tolist())\n","        if missing_cols:\n","            raise ValueError(f\"Missing columns in the dataset: {missing_cols}\")\n","\n","        df = df[relevant_columns].copy()\n","        df['issue_d'] = pd.to_datetime(df['issue_d'], errors='coerce')\n","        df['issue_year'] = df['issue_d'].dt.year\n","\n","        return df\n","\n","    except Exception as e:\n","        print(f\"An error occurred while preparing data: {e}\")\n","        raise\n","\n","def encode_features(df):\n","    if 'loan_status' not in df or df['loan_status'].isnull().any():\n","        raise ValueError(\"The 'loan_status' column is missing or contains null values.\")\n","\n","    unique_labels = df['loan_status'].unique()\n","    expected_labels = ['Default', 'Fully Paid']\n","    if not set(unique_labels).issubset(expected_labels):\n","        raise ValueError(f\"Unexpected values in 'loan_status': {unique_labels}. Expected: {expected_labels}\")\n","\n","    df['loan_status'] = df['loan_status'].apply(lambda x: 1 if x == 'Default' else 0)\n","\n","    if df['loan_status'].isnull().any():\n","        raise ValueError(\"Encoding of 'loan_status' resulted in null values.\")\n","\n","    categorical_features = ['home_ownership', 'sub_grade']\n","    for column in categorical_features:\n","        le = LabelEncoder()\n","        df[column] = le.fit_transform(df[column].astype(str))\n","\n","    return df\n","\n","def train_model(X_train, y_train):\n","    model = DecisionTreeClassifier(random_state=42)\n","    model.fit(X_train, y_train)\n","    return model\n","\n","def evaluate_model(model, X_test, y_test):\n","    predictions = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, predictions)\n","    f1 = f1_score(y_test, predictions)\n","    report = classification_report(y_test, predictions, output_dict=True)\n","\n","    results = {\n","        'accuracy': accuracy,\n","        'f1_score': f1,\n","        'classification_report': report\n","    }\n","\n","    return results\n","\n","def save_results(results, output_file):\n","    report_df = pd.DataFrame(results['classification_report']).transpose()\n","    report_df.to_csv(output_file, index=True)\n","\n","    summary_df = pd.DataFrame({\n","        'Metric': ['Accuracy', 'F1 Score'],\n","        'Value': [results['accuracy'], results['f1_score']]\n","    })\n","    \n","    summary_df.to_csv(output_file, mode='a', index=False)\n","    print(f\"Results saved to {output_file}\")\n","\n","def visualize_tree(model, feature_names):\n","    print(\"Visualizing decision tree...\")\n","    dot_data = export_graphviz(model, out_file=None, \n","                                feature_names=feature_names,\n","                                class_names=['Fully Paid', 'Default'],\n","                                filled=True, rounded=True,  \n","                                special_characters=True)  \n","    graph = graphviz.Source(dot_data)  \n","    graph.render(\"decision_tree.pdf\")  # Save the tree as a PDF file\n","    graph.view()  # Open the tree visualization\n","\n","def main(df, output_file='evaluation_results.csv'):\n","    df = load_and_prepare_data(df)\n","    df = encode_features(df)\n","\n","    # Define features (X) and target (y)\n","    X = df.drop(['loan_status', 'issue_d'], axis=1)  # Drop target and datetime\n","    y = df['loan_status']\n","\n","    # Additional check for y\n","    if y.isnull().any() or not set(y.unique()).issubset([0, 1]):\n","        raise ValueError(\"The target variable 'loan_status' must be binary (0 or 1) and cannot contain null values.\")\n","\n","    # Split the data into training and test sets with stratification\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42, stratify=y\n","    )\n","\n","    # Scale the features to improve model performance\n","    print(\"Scaling features...\")\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    # Train the model\n","    print(\"Training model...\")\n","    model = train_model(X_train, y_train)\n","\n","    # Get feature importances and select the top 3 features\n","    print(\"Feature importances:\", model.feature_importances_)\n","    feature_importances = model.feature_importances_\n","    feature_names = X.columns\n","    top_features_indices = np.argsort(feature_importances)[-3:]  # Get indices of top 3 features\n","    top_features = feature_names[top_features_indices]\n","\n","    # Filter the data to keep only the top features\n","    print(\"Selecting top features...\")\n","    X_train_top = X_train[:, top_features_indices]\n","    X_test_top = X_test[:, top_features_indices]\n","\n","    # Train the model again with only the top 3 features\n","    print(\"Training model with only the top features...\")\n","    model_top = train_model(X_train_top, y_train)\n","\n","    # Evaluate the model with top features\n","    print(\"Evaluating model with only the top features...\")\n","    results = evaluate_model(model_top, X_test_top, y_test)  # Correctly pass y_test\n","\n","    # Save results to CSV\n","    save_results(results, output_file)\n","    visualize_tree(model_top, top_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c28b1e9fa03841a3a82ea67ba0d1267e","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":1,"execution_start":1728623110547,"source_hash":"ad168e13"},"outputs":[],"source":["import os\n","plist=[]\n","paths = [os.environ[\"SYNTH_N\"], os.environ[\"SYNTH_G\"],\n","        os.environ[\"FAKER\"], os.environ[\"FAKER_P\"], os.environ[\"CLEAN\"]]\n","\n","for p in paths:\n","    path = os.path.join(os.environ[\"PATH_START\"], p)\n","    plist.append(path)\n","\n","plist"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a5023a8b78534f2aaee31c47f07ece40","deepnote_cell_type":"code","execution_context_id":"5a13e94d-0ff4-4be4-8272-dec6c7b73577","execution_millis":27609897,"execution_start":1728623110599,"source_hash":"de3fa41c"},"outputs":[],"source":["# Get the filename for each path\n","for p in plist:\n","    # Get the basename of the path\n","    output_basename = os.path.basename(p)\n","    # Remove '.csv' from the basename\n","    output_basename = output_basename[:-4]\n","    output_basename = output_basename + '_d-tree_evaluation_results.csv'\n","    print(output_basename)\n","    df = pd.read_csv(p, low_memory=False)\n","    main(df, output_file=output_basename)"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"7ad248d5c2694f939d6f37f3ea65cacc","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
